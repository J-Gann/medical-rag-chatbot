{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach Using Opensearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gui hosted on [http://localhost:5601/app/home](http://localhost:5601/app/home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opensearch-py in /home/l0gically/miniconda3/envs/HDHW/lib/python3.11/site-packages (2.4.2)\n",
      "Requirement already satisfied: urllib3>=1.26.18 in /home/l0gically/miniconda3/envs/HDHW/lib/python3.11/site-packages (from opensearch-py) (1.26.18)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.4.0 in /home/l0gically/miniconda3/envs/HDHW/lib/python3.11/site-packages (from opensearch-py) (2.31.0)\n",
      "Requirement already satisfied: six in /home/l0gically/miniconda3/envs/HDHW/lib/python3.11/site-packages (from opensearch-py) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in /home/l0gically/miniconda3/envs/HDHW/lib/python3.11/site-packages (from opensearch-py) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /home/l0gically/miniconda3/envs/HDHW/lib/python3.11/site-packages (from opensearch-py) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/l0gically/miniconda3/envs/HDHW/lib/python3.11/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/l0gically/miniconda3/envs/HDHW/lib/python3.11/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opensearch-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from opensearchpy import OpenSearch\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://opensearch.org/docs/latest/clients/python-low-level/\n",
    "\n",
    "host = 'localhost'\n",
    "port = 9200\n",
    "auth = ('admin', 'admin')\n",
    "\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_compress = True, # enables gzip compression for request bodies\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'pub_med_index'\n",
    "index_body = {  \n",
    "    'settings': {\n",
    "    'index': {\n",
    "      'number_of_shards': 4\n",
    "    },\n",
    "      'mappings': {\n",
    "        # Your index mappings here\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "response = client.indices.create(index_name, body=index_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_data_path = \"/home/chris/University/NLP_project/pubmed_data.json\"\n",
    "pubmed_data_preprocessed_path = \"/home/chris/University/NLP_project/pubmed_data_preprocessed.json\"\n",
    "\n",
    "if not os.path.exists(pubmed_data_preprocessed_path):\n",
    "  with open(pubmed_data_path, 'r') as f:\n",
    "    records = json.loads(f.read())\n",
    "     \n",
    "  records = records[\"PubmedArticle\"]\n",
    "  preprocessed_records = []\n",
    "  for idx, article in enumerate(records):\n",
    "      if (not \"Abstract\" in article[\"MedlineCitation\"][\"Article\"].keys()): continue\n",
    "      article = {\n",
    "          \"_id\": article[\"MedlineCitation\"][\"PMID\"],\n",
    "          \"title\": article[\"MedlineCitation\"][\"Article\"][\"ArticleTitle\"],\n",
    "          \"text\": \" \".join(article[\"MedlineCitation\"][\"Article\"][\"Abstract\"][\"AbstractText\"]) # some abstracts are split in an array\n",
    "      }\n",
    "      response\n",
    "      preprocessed_records.append(article)\n",
    "  with open(pubmed_data_preprocessed_path, 'w') as f:\n",
    "    f.write(json.dumps(preprocessed_records))\n",
    "else:\n",
    "    with open(pubmed_data_preprocessed_path, 'r') as f:\n",
    "        preprocessed_records = json.loads(f.read())\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': '38085539',\n",
       "  'title': 'High Seebeck Coefficient Inorganic Ge<sub>15</sub>Ga<sub>10</sub>Te<sub>75</sub> Core/Polymer Cladding Fibers for Respiration and Body Temperature Monitoring.',\n",
       "  'text': 'Wearable thermal sensors based on thermoelectric (TE) materials with high sensitivity and temperature resolution are extensively used in medical diagnosis, human-machine interfaces, and advanced artificial intelligence. However, their development is greatly limited by the lack of materials with both a high Seebeck coefficient and superior anticrystallization ability. Here, a new inorganic amorphous TE material, Ge<sub>15</sub>Ga<sub>10</sub>Te<sub>75</sub>, with a high Seebeck coefficient of 1109 μV/K is reported. Owing to the large difference between the glass-transition temperature and initial crystallization temperature, Ge<sub>15</sub>Ga<sub>10</sub>Te<sub>75</sub> strongly inhibits crystallization during fiber fabrication by thermally codrawing a precast rod comprising a Ge<sub>15</sub>Ga<sub>10</sub>Te<sub>75</sub> core and PP polymer cladding. The temperature difference can be effectively transduced into electrical signals to achieve TE fiber thermal sensing with an accurate temperature resolution of 0.03 K and a fast response time of 4 s. It is important to note that after the 1.5 and 5.5 K temperatures changed repeatedly, the TE properties of the fiber demonstrated high stability. Based on the Seebeck effect and superior flexibility of the fibers, they can be integrated into a mask and wearable fabric for human respiration and body temperature monitoring. The superior thermal sensing performance of the TE fibers together with their natural flexibility and scalable fabrication endow them with promising applications in health-monitoring and intelligent medical systems.'},\n",
       " {'_id': '38085351',\n",
       "  'title': 'Neuro-fuzzy modelling of a continuous stirred tank bioreactor with ceramic membrane technology for treating petroleum refinery effluent: a case study from Assam, India.',\n",
       "  'text': 'A continuous stirred tank bioreactor (CSTB) with cell recycling combined with ceramic membrane technology and inoculated with Rhodococcus opacus PD630 was employed to treat petroleum refinery wastewater for simultaneous chemical oxygen demand (COD) removal and lipid production from the retentate obtained during wastewater treatment. In the present study, the COD removal efficiency (COD<sub>RE</sub>) (%) and lipid concentration (g/L) were predicted using two artificial intelligence models, i.e., an artificial neural network (ANN) and a neuro-fuzzy neural network (NF-NN) with a network topology of 6-25-2 being the best for NF-NN. The results revealed the superiority of NF-NN over ANN in terms of determination coefficient (R<sup>2</sup>), root mean square error (RMSE), and mean absolute percentage error (MAPE). Three learning algorithms were tested with NF-NN; among them, the Bayesian regularization backpropagation (BR-BP) outperformed others. The sensitivity analysis revealed that, if solid retention time and biomass concentrations were maintained between 35 and 75\\xa0h and 3.0\\xa0g/L and 3.5\\xa0g/L, respectively, high COD<sub>RE</sub> (93%) and lipid concentration (2.8\\xa0g/L) could be obtained consistently.'},\n",
       " {'_id': '38085285',\n",
       "  'title': '[Quality indicators artificial intelligence].',\n",
       "  'text': 'The ability of some artificial intelligence (AI) systems to autonomously evolve and the sometimes very limited possibilities to comprehend their decision-making processes present new challenges to our legal system. At a European level this has led to reform efforts, of which the proposal for a\\xa0European AI regulation promises to close regulatory gaps in existing product safety law through cross-sectoral AI-specific safety requirements. A\\xa0prerequisite, however, would be that the EU legislator does not only avoid duplications and contradictions with existing safety requirements but also refrains from imposing exaggerated and unattainable demands. If this were to be taken into consideration, the new safety requirements could also be used to specify the undefined standard of care in liability law. Nevertheless, challenges in the context of provability continue to remain unresolved, posing a\\xa0risk of rendering the legal protection efforts of the aggrieved party ineffective. It remains to be seen whether the EU legislator will address this need for reform with the recently proposed reform of product liability law by the Commission.'},\n",
       " {'_id': '38085134',\n",
       "  'title': 'Ultrafast Dynamic Contrast-Enhanced MRI of the Breast: From Theory to Practice.',\n",
       "  'text': 'The development of ultrafast dynamic contrast-enhanced (UF-DCE) MRI has occurred in tandem with fast MRI scan techniques, particularly view-sharing and compressed sensing. Understanding the strengths of each technique and optimizing the relevant parameters are essential to their implementation. UF-DCE MRI has now shifted from research protocols to becoming a part of clinical scan protocols for breast cancer. UF-DCE MRI is expected to compensate for the low specificity of abbreviated MRI by adding kinetic information from the upslope of the time-intensity curve. Because kinetic information from UF-DCE MRI is obtained from the shape and timing of the initial upslope, various new kinetic parameters have been proposed. These parameters may be associated with receptor status or prognostic markers for breast cancer. In addition to the diagnosis of malignant lesions, more emphasis has been placed on predicting and evaluating treatment response because hyper-vascularity is linked to the aggressiveness of breast cancers. In clinical practice, it is important to note that breast lesion images obtained from UF-DCE MRI are slightly different from those obtained by conventional DCE MRI in terms of morphology. A major benefit of using UF-DCE MRI is avoidance of the marked or moderate background parenchymal enhancement (BPE) that can obscure the target enhancing lesions. BPE is less prominent in the earlier phases of UF-DCE MRI, which offers better lesion-to-noise contrast. The excellent contrast of early-enhancing vessels provides a key to understanding the detailed pathological structure of tumor-associated vessels. UF-DCE MRI is normally accompanied by a large volume of image data for which automated/artificial intelligence-based processing is expected to be useful. In this review, both the theoretical and practical aspects of UF-DCE MRI are summarized. EVIDENCE LEVEL: 5 TECHNICAL EFFICACY: Stage 2.'},\n",
       " {'_id': '38085079',\n",
       "  'title': 'Using AI to Improve Radiologist Performance in Detection of Abnormalities on Chest Radiographs.',\n",
       "  'text': 'Background Chest radiography remains the most common radiologic examination, and interpretation of its results can be difficult. Purpose To explore the potential benefit of artificial intelligence (AI) assistance in the detection of thoracic abnormalities on chest radiographs by evaluating the performance of radiologists with different levels of expertise, with and without AI assistance. Materials and Methods Patients who underwent both chest radiography and thoracic CT within 72 hours between January 2010 and December 2020 in a French public hospital were screened retrospectively. Radiographs were randomly included until reaching 500 radiographs, with about 50% of radiographs having abnormal findings. A senior thoracic radiologist annotated the radiographs for five abnormalities (pneumothorax, pleural effusion, consolidation, mediastinal and hilar mass, lung nodule) based on the corresponding CT results (ground truth). A total of 12 readers (four thoracic radiologists, four general radiologists, four radiology residents) read half the radiographs without AI and half the radiographs with AI (ChestView; Gleamer). Changes in sensitivity and specificity were measured using paired <i>t</i> tests. Results The study included 500 patients (mean age, 54 years ± 19 [SD]; 261 female, 239 male), with 522 abnormalities visible on 241 radiographs. On average, for all readers, AI use resulted in an absolute increase in sensitivity of 26% (95% CI: 20, 32), 14% (95% CI: 11, 17), 12% (95% CI: 10, 14), 8.5% (95% CI: 6, 11), and 5.9% (95% CI: 4, 8) for pneumothorax, consolidation, nodule, pleural effusion, and mediastinal and hilar mass, respectively (<i>P</i> < .001). Specificity increased with AI assistance (3.9% [95% CI: 3.2, 4.6], 3.7% [95% CI: 3, 4.4], 2.9% [95% CI: 2.3, 3.5], and 2.1% [95% CI: 1.6, 2.6] for pleural effusion, mediastinal and hilar mass, consolidation, and nodule, respectively), except in the diagnosis of pneumothorax (-0.2%; 95% CI: -0.36, -0.04; <i>P</i> = .01). The mean reading time was 81 seconds without AI versus 56 seconds with AI (31% decrease, <i>P</i> < .001). Conclusion AI-assisted chest radiography interpretation resulted in absolute increases in sensitivity for all radiologists of various levels of expertise and reduced the reading times; specificity increased with AI, except in the diagnosis of pneumothorax. © RSNA, 2023 <i>Supplemental material is available for this article.</i>'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc for doc in preprocessed_records[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [ \n",
    "    ({\"index\": {\"_index\": \"pub_med_index\", \"_id\":doc[\"_id\"] }},{\"title\": doc[\"title\"], \"text\": doc[\"text\"] })\n",
    "for doc in preprocessed_records[:3] \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = '\\n'.join([f'{json.dumps(item, indent=None, separators=(\",\", \":\"))}' for tpl in actions for item in tpl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulk request successful.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = client.bulk(body=request, refresh=True)\n",
    "    print(\"Bulk request successful.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to perform bulk request. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'pub_med_index'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define an index mapping with a custom analyzer\n",
    "index_mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text_field\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"custom_analyzer\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"custom_analyzer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\"lowercase\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the index with the custom mapping\n",
    "index_name = \"pub_med_index\"\n",
    "client.indices.create(index=index_name, body=index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'pub_med_index'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define an index mapping with a custom analyzer\n",
    "index_mapping = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"custom_analyzer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\"lowercase\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the index with the custom mapping\n",
    "index_name = \"pub_med_index\"\n",
    "client.indices.create(index=index_name, body=index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulk request successful.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = client.bulk(body=request, refresh=True)\n",
    "    print(\"Bulk request successful.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to perform bulk request. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index a document with the text field\n",
    "document = {\n",
    "    \"text_field\": \"This is a sample text.\"\n",
    "}\n",
    "\n",
    "client.index(index=index_name, body=document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = client.indices.get_alias(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".plugins-ml-config\n",
      ".opensearch-observability\n",
      ".ql-datasources\n",
      "security-auditlog-2024.01.19\n",
      ".opensearch-sap-log-types-config\n",
      ".kibana_92668751_admin_1\n",
      ".kibana_1\n",
      ".opendistro_security\n",
      "security-auditlog-2024.01.21\n"
     ]
    }
   ],
   "source": [
    "for index in indices:\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'pub_med_index'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define an index mapping with a custom analyzer\n",
    "index_mapping = {\n",
    "  \"settings\": {\n",
    "    \"index\": {\n",
    "      \"knn\": True,\n",
    "      \"knn.algo_param.ef_search\": 100\n",
    "    }\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"title\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"standard\"\n",
    "      },\n",
    "      \"text\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"standard\"\n",
    "      },\n",
    "      \"vector\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": 5  \n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "# Create the index with the custom mapping\n",
    "index_name = \"pub_med_index\"\n",
    "client.indices.create(index=index_name, body=index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'pub_med_index'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define an index mapping with a custom analyzer\n",
    "index_mapping = {\n",
    "  \"settings\": {\n",
    "    \"index.knn\": True\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"title\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"standard\"\n",
    "      },\n",
    "      \"text\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"standard\"\n",
    "      },\n",
    "      \"vector\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": 5  \n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "# Create the index with the custom mapping\n",
    "index_name = \"pub_med_index\"\n",
    "client.indices.create(index=index_name, body=index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [ \n",
    "    ({\"index\": {\"_index\": \"pub_med_index\", \"_id\":doc[\"_id\"] }},{\"title\": doc[\"title\"], \"text\": doc[\"text\"], \"vector\": [num,num,num,num,num] })\n",
    "for num,doc in enumerate(preprocessed_records[:5])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = '\\n'.join([f'{json.dumps(item, indent=None, separators=(\",\", \":\"))}' for tpl in actions for item in tpl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulk request successful.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = client.bulk(body=request, refresh=True)\n",
    "    print(\"Bulk request successful.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to perform bulk request. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "npl_env",
   "language": "python",
   "name": "npl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
