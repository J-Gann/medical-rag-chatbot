{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3395f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Bio import Medline\n",
    "import os\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModel, BertForSequenceClassification, AutoModelForQuestionAnswering\n",
    "from opensearchpy import OpenSearch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d1222cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = \"cuda:0\"\n",
    "else:\n",
    "  device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d90da2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'pub_med_index'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host = 'localhost'\n",
    "port = 9200\n",
    "auth = ('admin', 'qaOllama2')\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_compress = True, # enables gzip compression for request bodies\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False,\n",
    ")\n",
    "\n",
    "#index_name = 'pub_med_index'\n",
    "#client.indices.delete(index=index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5979e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_data_path = \"/home/paperspace/pubmed_data\"\n",
    "pubmed_data_preprocessed_path = \"/home/paperspace/pubmed_data_preprocessed.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab5aece0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59038\n"
     ]
    }
   ],
   "source": [
    "records=[]\n",
    "missed=0\n",
    "num=0\n",
    "with open(pubmed_data_path) as stream:\n",
    "    for article in Medline.parse(stream):\n",
    "        if not \"PMID\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"TI\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"FAU\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"DP\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"AB\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "        num+=1\n",
    "        records.append(article)\n",
    "\n",
    "with open(pubmed_data_preprocessed_path, 'w') as f:\n",
    "    f.write(json.dumps(records))\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d026ab",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "537b73c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PubMedDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "          self.data = json.loads(f.read())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx][\"AB\"]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48faab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "387e26a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PubMedDataset(pubmed_data_preprocessed_path)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e2c3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(last_hidden_state, attention_mask):\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "    return torch.sum(last_hidden_state * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c7c907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for i, sample in enumerate(dataloader):\n",
    "        inputs = tokenizer(sample, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        out = model(**inputs)\n",
    "        pooled = mean_pooling(out.last_hidden_state, inputs[\"attention_mask\"]).to(device)\n",
    "        embeddings.extend(pooled)\n",
    "embeddings_stacked = torch.stack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46969c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embeddings_stacked, '/home/paperspace/pubmed_data_embeddings.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d163271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_stacked=torch.load('/home/paperspace/pubmed_data_embeddings.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c0864d",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1c4ca5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index_name = 'pub_med_index'\n",
    "#client.indices.delete(index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a320c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'pub_med_index'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define an index mapping with a custom analyzer\n",
    "index_mapping = {\n",
    "  \"settings\": {\n",
    "    \"index.knn\": True\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"title\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"standard\"\n",
    "      },\n",
    "      \"TI\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"standard\"\n",
    "      },\n",
    "      \"AB\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"standard\"\n",
    "      },\n",
    "      \"vector\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": len(embeddings_stacked[0])  \n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "# Create the index with the custom mapping\n",
    "index_name = \"pub_med_index\"\n",
    "client.indices.create(index=index_name, body=index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75f05853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n",
      "Bulk request successful.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "for i in range(0, len(records), batch_size):\n",
    "    batch = records[i:i + batch_size]\n",
    "    actions = [ \n",
    "    ({\"index\": {\"_index\": \"pub_med_index\",\n",
    "                \"_id\":doc[\"PMID\"]}},\n",
    "     {\"TI\":doc[\"TI\"],\n",
    "      \"AB\":doc[\"AB\"],\n",
    "      \"vector\":embeddings_stacked[num].tolist()\n",
    "    }\n",
    "    )\n",
    "    for num,doc in enumerate(batch)]\n",
    "    request = '\\n'.join([f'{json.dumps(item, indent=None, separators=(\",\", \":\"))}' for tpl in actions for item in tpl])\n",
    "    try:\n",
    "        response = client.bulk(body=request, refresh=True)\n",
    "        print(\"Bulk request successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to perform bulk request. Error: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3d3f474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pinecone import Pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from Bio import Medline\n",
    "import ollama\n",
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "\n",
    "from opensearchpy import OpenSearch\n",
    "from transformers import AutoTokenizer, AutoModel, BertForSequenceClassification, AutoModelForQuestionAnswering\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = \"cuda:0\"\n",
    "else:\n",
    "  device = \"cpu\"\n",
    "device\n",
    "\n",
    "records = {}\n",
    "missed = 0\n",
    "\n",
    "with open(pubmed_data_path) as stream:    \n",
    "    for article in Medline.parse(stream):\n",
    "\n",
    "        if not \"PMID\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"TI\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"FAU\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"DP\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"AB\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "        \n",
    "        records[article[\"PMID\"]] = article\n",
    "\n",
    "#model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2').to(device)\n",
    "\n",
    "# why not take cls token?\n",
    "def mean_pooling(last_hidden_state, attention_mask):\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "    return torch.sum(last_hidden_state * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# https://opensearch.org/docs/latest/clients/python-low-level/\n",
    "\n",
    "host = 'localhost'\n",
    "port = 9200\n",
    "auth = ('admin', 'qaOllama2')\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_compress = True, # enables gzip compression for request bodies\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False,\n",
    ")\n",
    "\n",
    "index_name = 'pub_med_index'\n",
    "\n",
    "def retrieve_documents(question):\n",
    "    \n",
    "    inputs = tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    query_outputs = mean_pooling(model(**inputs).last_hidden_state, inputs[\"attention_mask\"]).to(\"cpu\")\n",
    "    print(len(query_outputs[0].tolist()))\n",
    "\n",
    "    # Define the KNN search query\n",
    "    knn_query = {\n",
    "        \"size\": 1,\n",
    "        \"_source\": [\"title\", \"text\"],\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"vector\": {\n",
    "                    \"vector\": query_outputs[0].tolist(),\n",
    "                    \"k\": 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Perform the KNN search\n",
    "    response = client.search(index=index_name, body=knn_query)\n",
    "    \n",
    "    return [(res['_id'], res['_score']) for res in response['hits']['hits'][:]]\n",
    "    \n",
    "\n",
    "def generate(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    return {\"answer\": [f\"DOCUMENT-ID: {records[id]['PMID']}\\n FULL-AUTHOR: {records[id]['FAU']}\\n PUBLICATION-DATE: {records[id]['DP']}\\n TEXT: {records[id]['AB']}\\n SCORE: {round(score,2)} \\n DOCUMENT-TITLE: {records[id]['TI']}\" for id,score in documents]}\n",
    "\n",
    "\n",
    "answer = generate(\"Why is alcohol bad?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "37cdab22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': ['DOCUMENT-ID: 29463182\\n FULL-AUTHOR: [\"O\\'Donnell, Michael\", \\'Nelson, Leif D\\', \\'Ackermann, Evi\\', \\'Aczel, Balazs\\', \\'Akhtar, Athfah\\', \\'Aldrovandi, Silvio\\', \\'Alshaif, Nasseem\\', \\'Andringa, Ronald\\', \\'Aveyard, Mark\\', \\'Babincak, Peter\\', \\'Balatekin, Nursena\\', \\'Baldwin, Scott A\\', \\'Banik, Gabriel\\', \\'Baskin, Ernest\\', \\'Bell, Raoul\\', \\'Bialobrzeska, Olga\\', \\'Birt, Angie R\\', \\'Boot, Walter R\\', \\'Braithwaite, Scott R\\', \\'Briggs, Jessie C\\', \\'Buchner, Axel\\', \\'Budd, Desiree\\', \\'Budzik, Kathryn\\', \\'Bullens, Lottie\\', \\'Bulley, Richard L\\', \\'Cannon, Peter R\\', \\'Cantarero, Katarzyna\\', \\'Cesario, Joseph\\', \\'Chambers, Stephanie\\', \\'Chartier, Christopher R\\', \\'Chekroun, Peggy\\', \\'Chong, Clara\\', \\'Cleeremans, Axel\\', \\'Coary, Sean P\\', \\'Coulthard, Jacob\\', \\'Cramwinckel, Florien M\\', \\'Denson, Thomas F\\', \\'Diaz-Lago, Marcos\\', \\'DiDonato, Theresa E\\', \\'Drummond, Aaron\\', \\'Eberlen, Julia\\', \\'Ebersbach, Titus\\', \\'Edlund, John E\\', \\'Finnigan, Katherine M\\', \\'Fisher, Justin\\', \\'Frankowska, Natalia\\', \\'Garcia-Sanchez, Efrain\\', \\'Golom, Frank D\\', \\'Graves, Andrew J\\', \\'Greenberg, Kevin\\', \\'Hanioti, Mando\\', \\'Hansen, Heather A\\', \\'Harder, Jenna A\\', \\'Harrell, Erin R\\', \\'Hartanto, Andree\\', \\'Inzlicht, Michael\\', \\'Johnson, David J\\', \\'Karpinski, Andrew\\', \\'Keller, Victor N\\', \\'Klein, Olivier\\', \\'Koppel, Lina\\', \\'Krahmer, Emiel\\', \\'Lantian, Anthony\\', \\'Larson, Michael J\\', \\'Legal, Jean-Baptiste\\', \\'Lucas, Richard E\\', \\'Lynott, Dermot\\', \\'Magaldino, Corey M\\', \\'Massar, Karlijn\\', \\'McBee, Matthew T\\', \\'McLatchie, Neil\\', \\'Melia, Nadhilla\\', \\'Mensink, Michael C\\', \\'Mieth, Laura\\', \\'Moore-Berg, Samantha\\', \\'Neeser, Geraldine\\', \\'Newell, Ben R\\', \\'Noordewier, Marret K\\', \\'Ali Ozdogru, Asil\\', \\'Pantazi, Myrto\\', \\'Parzuchowski, Michal\\', \\'Peters, Kim\\', \\'Philipp, Michael C\\', \\'Pollmann, Monique M H\\', \\'Rentzelas, Panagiotis\\', \\'Rodriguez-Bailon, Rosa\\', \\'Philipp Roer, Jan\\', \\'Ropovik, Ivan\\', \\'Roque, Nelson A\\', \\'Rueda, Carolina\\', \\'Rutjens, Bastiaan T\\', \\'Sackett, Katey\\', \\'Salamon, Janos\\', \\'Sanchez-Rodriguez, Angel\\', \\'Saunders, Blair\\', \\'Schaafsma, Juliette\\', \\'Schulte-Mecklenbeck, Michael\\', \\'Shanks, David R\\', \\'Sherman, Martin F\\', \\'Steele, Kenneth M\\', \\'Steffens, Niklas K\\', \\'Sun, Jessie\\', \\'Susa, Kyle J\\', \\'Szaszi, Barnabas\\', \\'Szollosi, Aba\\', \\'Tamayo, Ricardo M\\', \\'Tinghog, Gustav\\', \\'Tong, Yuk-Yue\\', \\'Tweten, Carol\\', \\'Vadillo, Miguel A\\', \\'Valcarcel, Deisy\\', \\'Van der Linden, Nicolas\\', \\'van Elk, Michiel\\', \\'van Harreveld, Frenk\\', \\'Vastfjall, Daniel\\', \\'Vazire, Simine\\', \\'Verduyn, Philippe\\', \\'Williams, Matt N\\', \\'Willis, Guillermo B\\', \\'Wood, Sarah E\\', \\'Yang, Chunliang\\', \\'Zerhouni, Oulmann\\', \\'Zheng, Robert\\', \\'Zrubka, Mark\\']\\n PUBLICATION-DATE: 2018 Mar\\n TEXT: Dijksterhuis and van Knippenberg (1998) reported that participants primed with a category associated with intelligence (\"professor\") subsequently performed 13% better on a trivia test than participants primed with a category associated with a lack of intelligence (\"soccer hooligans\"). In two unpublished replications of this study designed to verify the appropriate testing procedures, Dijksterhuis, van Knippenberg, and Holland observed a smaller difference between conditions (2%-3%) as well as a gender difference: Men showed the effect (9.3% and 7.6%), but women did not (0.3% and -0.3%). The procedure used in those replications served as the basis for this multilab Registered Replication Report. A total of 40 laboratories collected data for this project, and 23 of these laboratories met all inclusion criteria. Here we report the meta-analytic results for those 23 direct replications (total N = 4,493), which tested whether performance on a 30-item general-knowledge trivia task differed between these two priming conditions (results of supplementary analyses of the data from all 40 labs, N = 6,454, are also reported). We observed no overall difference in trivia performance between participants primed with the \"professor\" category and those primed with the \"hooligan\" category (0.14%) and no moderation by gender.\\n SCORE: 0.1 \\n DOCUMENT-TITLE: Registered Replication Report: Dijksterhuis and van Knippenberg (1998).']}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
