{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Bio import Medline\n",
    "import os\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModel, BertForSequenceClassification, AutoModelForQuestionAnswering\n",
    "from opensearchpy import OpenSearch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = \"cuda:0\"\n",
    "else:\n",
    "  device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'localhost'\n",
    "port = 9200\n",
    "auth = ('admin', 'qaOllama2')\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_compress = True, # enables gzip compression for request bodies\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False,\n",
    ")\n",
    "\n",
    "#index_name = 'pub_med_index'\n",
    "#client.indices.delete(index=index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_data_path = \"/home/paperspace/pubmed_data\"\n",
    "pubmed_data_preprocessed_path = \"/home/paperspace/pubmed_data_preprocessed.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records=[]\n",
    "missed=0\n",
    "num=0\n",
    "with open(pubmed_data_path) as stream:\n",
    "    for article in Medline.parse(stream):\n",
    "        if not \"PMID\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"TI\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"FAU\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"DP\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"AB\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "        num+=1\n",
    "        records.append(article)\n",
    "\n",
    "with open(pubmed_data_preprocessed_path, 'w') as f:\n",
    "    f.write(json.dumps(records))\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PubMedDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "          self.data = json.loads(f.read())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx][\"AB\"]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PubMedDataset(pubmed_data_preprocessed_path)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(last_hidden_state, attention_mask):\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "    return torch.sum(last_hidden_state * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for i, sample in enumerate(dataloader):\n",
    "        inputs = tokenizer(sample, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        out = model(**inputs)\n",
    "        pooled = mean_pooling(out.last_hidden_state, inputs[\"attention_mask\"]).to(device)\n",
    "        embeddings.extend(pooled)\n",
    "embeddings_stacked = torch.stack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embeddings_stacked, '/home/paperspace/pubmed_data_embeddings.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_stacked=torch.load('/home/paperspace/pubmed_data_embeddings.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index_name = 'pub_med_index'\n",
    "#client.indices.delete(index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an index mapping with a custom analyzer\n",
    "index_mapping = {\n",
    "  \"settings\": {\n",
    "    \"index.knn\": True\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"title\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"standard\"\n",
    "      },\n",
    "      \"TI\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"standard\"\n",
    "      },\n",
    "      \"AB\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"standard\"\n",
    "      },\n",
    "      \"vector\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": len(embeddings_stacked[0])  \n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "# Create the index with the custom mapping\n",
    "index_name = \"pub_med_index\"\n",
    "client.indices.create(index=index_name, body=index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "for i in range(0, len(records), batch_size):\n",
    "    batch = records[i:i + batch_size]\n",
    "    actions = [ \n",
    "    ({\"index\": {\"_index\": \"pub_med_index\",\n",
    "                \"_id\":doc[\"PMID\"]}},\n",
    "     {\"TI\":doc[\"TI\"],\n",
    "      \"AB\":doc[\"AB\"],\n",
    "      \"vector\":embeddings_stacked[num].tolist()\n",
    "    }\n",
    "    )\n",
    "    for num,doc in enumerate(batch)]\n",
    "    request = '\\n'.join([f'{json.dumps(item, indent=None, separators=(\",\", \":\"))}' for tpl in actions for item in tpl])\n",
    "    try:\n",
    "        response = client.bulk(body=request, refresh=True)\n",
    "        print(\"Bulk request successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to perform bulk request. Error: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pinecone import Pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from Bio import Medline\n",
    "import ollama\n",
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "\n",
    "from opensearchpy import OpenSearch\n",
    "from transformers import AutoTokenizer, AutoModel, BertForSequenceClassification, AutoModelForQuestionAnswering\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = \"cuda:0\"\n",
    "else:\n",
    "  device = \"cpu\"\n",
    "device\n",
    "\n",
    "records = {}\n",
    "missed = 0\n",
    "\n",
    "with open(pubmed_data_path) as stream:    \n",
    "    for article in Medline.parse(stream):\n",
    "\n",
    "        if not \"PMID\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"TI\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"FAU\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"DP\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "\n",
    "        if not \"AB\" in article:\n",
    "            missed += 1\n",
    "            continue\n",
    "        \n",
    "        records[article[\"PMID\"]] = article\n",
    "\n",
    "#model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2').to(device)\n",
    "\n",
    "# why not take cls token?\n",
    "def mean_pooling(last_hidden_state, attention_mask):\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "    return torch.sum(last_hidden_state * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# https://opensearch.org/docs/latest/clients/python-low-level/\n",
    "\n",
    "host = 'localhost'\n",
    "port = 9200\n",
    "auth = ('admin', 'qaOllama2')\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_compress = True, # enables gzip compression for request bodies\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False,\n",
    ")\n",
    "\n",
    "index_name = 'pub_med_index'\n",
    "\n",
    "def retrieve_documents(question):\n",
    "    \n",
    "    #inputs = tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    #query_outputs = mean_pooling(model(**inputs).last_hidden_state, inputs[\"attention_mask\"]).to(device)\n",
    "    \n",
    "    #print(query_outputs)\n",
    "    \n",
    "    model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    vector=model.encode([question])[0].tolist()\n",
    "\n",
    "    # Define the KNN search query\n",
    "    knn_query = {\n",
    "        \"size\": 5,\n",
    "        \"_source\": [\"TI\", \"AB\"],\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"vector\": {\n",
    "                    \"vector\": vector,\n",
    "                    \"k\": 5\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Perform the KNN search\n",
    "    response = client.search(index=index_name, body=knn_query)\n",
    "    \n",
    "    print(response)\n",
    "    \n",
    "    return [(res['_id'], res['_score']) for res in response['hits']['hits'][:]]\n",
    "    \n",
    "\n",
    "def generate(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    return {\"answer\": [f\"DOCUMENT-ID: {records[id]['PMID']}\\n FULL-AUTHOR: {records[id]['FAU']}\\n PUBLICATION-DATE: {records[id]['DP']}\\n TEXT: {records[id]['AB']}\\n SCORE: {round(score,2)} \\n DOCUMENT-TITLE: {records[id]['TI']}\" for id,score in documents]}\n",
    "\n",
    "\n",
    "answer = generate(\"Why is alcohol bad?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
