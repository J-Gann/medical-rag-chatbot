{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cheung0/Download-PubMed-Abstracts-with-Python-Tool/blob/main/Download_PubMed_abstracts_with_Python_Tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIQY5-TMtwLx"
   },
   "source": [
    "# Download PubMed abstracts with Python Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfmuJ1uvtwL0"
   },
   "source": [
    "If you're a medical student, or doctor, or are trying to read PubMed articles relating to your medicine or medical condition, this Python tool's for you. It downloads PubMed abstracts in a text file, allowing you to read them faster. It helps you save time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scpoQXUAtwLz"
   },
   "source": [
    "By: [Michael Cheung](https://www.linkedin.com/in/michael-cheung0/)\n",
    "\n",
    "Credits:\n",
    "[GitHub Repo](https://github.com/erilu/pubmed-abstract-compiler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8IXv7A12TgW"
   },
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "joR-u4aztwL_"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import urllib\n",
    "from time import sleep\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piSPudG070Dh"
   },
   "source": [
    "**Specify search query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pls5xKI2twMA",
    "outputId": "2774a3a5-2351-477a-f6f9-4d3b74c726d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Intelligence\n"
     ]
    }
   ],
   "source": [
    "# Specify your search query here. Works on single words or multiple words.\n",
    "# query = 'P2RY8'\n",
    "query = 'Intelligence'\n",
    "\n",
    "# Formats query in correct format\n",
    "def format_query(search_query):\n",
    "    if ' ' not in search_query:\n",
    "        query = search_query\n",
    "    else:\n",
    "        query = '\"' + '+'.join(search_query.split()) + '\"'\n",
    "    return query\n",
    "\n",
    "query = format_query(query)\n",
    "print(\"Query: \" + query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oICGunYQ9m5e"
   },
   "source": [
    "**Url with abstract ids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RsgDHOAwtwMB",
    "outputId": "249acb72-270e-46b6-ff69-ec2aa3ed3c14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term=Intelligence&usehistory=y&rettype=json\n"
     ]
    }
   ],
   "source": [
    "# common settings between esearch and efetch\n",
    "base_url = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/'\n",
    "db = 'db=pubmed'\n",
    "\n",
    "# esearch specific settings\n",
    "search_eutil = 'esearch.fcgi?'\n",
    "search_term = '&term=' + query\n",
    "search_usehistory = '&usehistory=y'\n",
    "search_rettype = '&rettype=json'\n",
    "\n",
    "search_url = base_url+search_eutil+db+search_term+search_usehistory+search_rettype\n",
    "print(search_url)\n",
    "\n",
    "f = urllib.request.urlopen(search_url)\n",
    "search_data = f.read().decode('utf-8')\n",
    "\n",
    "# obtain total abstract count\n",
    "total_abstract_count = int(re.findall(\"<Count>(\\d+?)</Count>\",search_data)[0])\n",
    "\n",
    "# obtain webenv and querykey settings for efetch command\n",
    "fetch_webenv = \"&WebEnv=\" + re.findall (\"<WebEnv>(\\S+)<\\/WebEnv>\", search_data)[0]\n",
    "fetch_querykey = \"&query_key=\" + re.findall(\"<QueryKey>(\\d+?)</QueryKey>\",search_data)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QCy3NkqtwMC"
   },
   "source": [
    "**Url with abstract summaries**\n",
    "\n",
    "You can further filter results by changing optional values. For example, change retmax (return max) to limit amount of abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lB5Z7e5HtwMC",
    "outputId": "cdcc18b1-4daf-4b2c-b5ab-079de3322f92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&query_key=1&WebEnv=MCID_65a2f51e0fc0bd750077b2ca&retstart=50&retmax=1&retmode=text&rettype=abstract\n"
     ]
    }
   ],
   "source": [
    "# other efetch settings\n",
    "fetch_eutil = 'efetch.fcgi?'\n",
    "retmax = 1\n",
    "retstart = 50\n",
    "fetch_retstart = \"&retstart=\" + str(retstart)\n",
    "fetch_retmax = \"&retmax=\" + str(retmax)\n",
    "fetch_retmode = \"&retmode=text\"\n",
    "fetch_rettype = \"&rettype=abstract\"\n",
    "\n",
    "fetch_url = base_url+fetch_eutil+db+fetch_querykey+fetch_webenv+fetch_retstart+fetch_retmax+fetch_retmode+fetch_rettype\n",
    "print(fetch_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZM-AgyB6Z-d"
   },
   "source": [
    "**Download the abstracts into a text file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n_phkXk-yCV3",
    "outputId": "b6c5b2ed-b085-465a-a6c0-19a19a46b3d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text saved to abstracts.txt\n"
     ]
    }
   ],
   "source": [
    "def download_webpage(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        return text\n",
    "    else:\n",
    "        print(\"Failed to download.\")\n",
    "        return None\n",
    "\n",
    "def save_text_to_file(text, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "    print(\"Text saved to\", filename)\n",
    "\n",
    "# Example usage:\n",
    "url = fetch_url\n",
    "filename = \"abstracts.txt\"\n",
    "\n",
    "webpage_text = download_webpage(url)\n",
    "if webpage_text:\n",
    "    save_text_to_file(webpage_text, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been written to pubmed_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def text_to_json(text):\n",
    "    # Extracting PMID\n",
    "    pmid_match = re.search(r'PMID:\\s*(\\d+)', text)\n",
    "    pmid = pmid_match.group(1) if pmid_match else None\n",
    "\n",
    "    # Extracting title\n",
    "    title_match = re.search(r'^([\\s\\S]+?)\\.\\s*\\d{4}\\s+[A-Za-z]+\\s+\\d+\\s*;\\d+\\(.+?\\):', text)\n",
    "    title = title_match.group(1).strip() if title_match else None\n",
    "\n",
    "    # Extracting abstract\n",
    "    abstract_start = re.search(r'(?<=\\n\\n)[\\s\\S]+?(?=\\n\\n)', text)\n",
    "    abstract = abstract_start.group(0).strip() if abstract_start else None\n",
    "\n",
    "    # Creating JSON structure\n",
    "    data = {\n",
    "        \"PMID\": pmid,\n",
    "        \"title\": title,\n",
    "        \"abstract\": abstract\n",
    "    }\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_to_json(data, output_file):\n",
    "    with open(output_file, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read text from a file\n",
    "    input_file = \"abstracts.txt\"\n",
    "\n",
    "    with open(input_file, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Convert text to JSON\n",
    "    pubmed_data = text_to_json(text)\n",
    "\n",
    "    # Save JSON data to a file\n",
    "    output_file = \"pubmed_data.json\"\n",
    "    save_to_json(pubmed_data, output_file)\n",
    "\n",
    "    print(f\"JSON data has been written to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?pubmed&retstart=50&retmax=1&retmode=xml&rettype=abstract\n",
      "JSON data has been written to pubmed_data.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Set up your E-utilities parameters\n",
    "base_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/'\n",
    "db = 'pubmed'\n",
    "fetch_eutil = 'efetch.fcgi?'\n",
    "retmax = 1\n",
    "retstart = 50\n",
    "fetch_retstart = \"&retstart=\" + str(retstart)\n",
    "fetch_retmax = \"&retmax=\" + str(retmax)\n",
    "fetch_retmode = \"&retmode=xml\"  # Change to \"&retmode=text\" if you prefer plain text\n",
    "fetch_rettype = \"&rettype=abstract\"\n",
    "\n",
    "fetch_url = base_url + fetch_eutil + db + fetch_retstart + fetch_retmax + fetch_retmode + fetch_rettype\n",
    "print(fetch_url)\n",
    "\n",
    "# Make the request\n",
    "response = requests.get(fetch_url)\n",
    "\n",
    "# Parse the XML response\n",
    "tree = ET.fromstring(response.content)\n",
    "\n",
    "# Extract PMID, title, and abstract\n",
    "pmid = tree.find(\".//PMID\").text if tree.find(\".//PMID\") is not None else None\n",
    "title = tree.find(\".//ArticleTitle\").text if tree.find(\".//ArticleTitle\") is not None else None\n",
    "abstract = tree.find(\".//AbstractText\").text if tree.find(\".//AbstractText\") is not None else None\n",
    "\n",
    "# Creating JSON structure with only PMID, title, and abstract\n",
    "data = {\n",
    "    \"PMID\": pmid,\n",
    "    \"title\": title,\n",
    "    \"abstract\": abstract\n",
    "}\n",
    "\n",
    "# Save JSON data to a file\n",
    "output_file = \"pubmed_data.json\"\n",
    "with open(output_file, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=2)\n",
    "\n",
    "print(f\"JSON data has been written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Intelligence\n",
      "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term=Intelligence&usehistory=y&rettype=json\n",
      "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&query_key=1&WebEnv=MCID_65a307e1126d074028431d80&retstart=50&retmax=1&retmode=xml&rettype=abstract\n",
      "JSON data has been written to pubmed_data.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify your search query here. Works on single words or multiple words.\n",
    "# query = 'P2RY8'\n",
    "query = 'Intelligence'\n",
    "\n",
    "# Formats query in correct format\n",
    "def format_query(search_query):\n",
    "    if ' ' not in search_query:\n",
    "        query = search_query\n",
    "    else:\n",
    "        query = '\"' + '+'.join(search_query.split()) + '\"'\n",
    "    return query\n",
    "\n",
    "query = format_query(query)\n",
    "print(\"Query: \" + query)\n",
    "\n",
    "# common settings between esearch and efetch\n",
    "base_url = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/'\n",
    "db = 'db=pubmed'\n",
    "\n",
    "# esearch specific settings\n",
    "search_eutil = 'esearch.fcgi?'\n",
    "search_term = '&term=' + query\n",
    "search_usehistory = '&usehistory=y'\n",
    "search_rettype = '&rettype=json'\n",
    "\n",
    "search_url = base_url + search_eutil + db + search_term + search_usehistory + search_rettype\n",
    "print(search_url)\n",
    "\n",
    "f = urllib.request.urlopen(search_url)\n",
    "search_data = f.read().decode('utf-8')\n",
    "\n",
    "# obtain total abstract count\n",
    "total_abstract_count = int(re.findall(\"<Count>(\\d+?)</Count>\", search_data)[0])\n",
    "\n",
    "# obtain webenv and querykey settings for efetch command\n",
    "fetch_webenv = \"&WebEnv=\" + re.findall(\"<WebEnv>(\\S+)<\\/WebEnv>\", search_data)[0]\n",
    "fetch_querykey = \"&query_key=\" + re.findall(\"<QueryKey>(\\d+?)</QueryKey>\", search_data)[0]\n",
    "\n",
    "# other efetch settings\n",
    "fetch_eutil = 'efetch.fcgi?'\n",
    "retmax = 1\n",
    "retstart = 50\n",
    "fetch_retstart = \"&retstart=\" + str(retstart)\n",
    "fetch_retmax = \"&retmax=\" + str(retmax)\n",
    "fetch_retmode = \"&retmode=xml\"  # Use XML for structured data\n",
    "fetch_rettype = \"&rettype=abstract\"\n",
    "\n",
    "fetch_url = base_url + fetch_eutil + db + fetch_querykey + fetch_webenv + fetch_retstart + fetch_retmax + fetch_retmode + fetch_rettype\n",
    "print(fetch_url)\n",
    "\n",
    "# Make the request to fetch the XML response\n",
    "response = requests.get(fetch_url)\n",
    "\n",
    "# Parse the XML response\n",
    "soup = BeautifulSoup(response.text, 'xml')\n",
    "\n",
    "# Extract PMID, title, and abstract\n",
    "pmid = soup.find(\"PMID\").text if soup.find(\"PMID\") else None\n",
    "title = soup.find(\"ArticleTitle\").text if soup.find(\"ArticleTitle\") else None\n",
    "abstract_tag = soup.find(\"AbstractText\")\n",
    "abstract = abstract_tag.text if abstract_tag else None\n",
    "\n",
    "# Creating JSON structure with only PMID, title, and abstract\n",
    "data = {\n",
    "    \"PMID\": pmid,\n",
    "    \"title\": title,\n",
    "    \"abstract\": abstract\n",
    "}\n",
    "\n",
    "# Save JSON data to a file\n",
    "output_file = \"pubmed_data.json\"\n",
    "with open(output_file, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=2)\n",
    "\n",
    "print(f\"JSON data has been written to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
