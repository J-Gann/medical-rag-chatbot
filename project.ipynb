{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: biopython in /home/jonas/.local/lib/python3.8/site-packages (1.81)\n",
      "Requirement already satisfied: numpy in /home/jonas/.local/lib/python3.8/site-packages (from biopython) (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xmltodict in /home/jonas/.local/lib/python3.8/site-packages (0.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opensearch-py in /home/jonas/.local/lib/python3.8/site-packages (2.4.2)\n",
      "Requirement already satisfied: urllib3>=1.26.18 in /home/jonas/.local/lib/python3.8/site-packages (from opensearch-py) (2.1.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.4.0 in /home/jonas/.local/lib/python3.8/site-packages (from opensearch-py) (2.31.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from opensearch-py) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil in /home/jonas/.local/lib/python3.8/site-packages (from opensearch-py) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /home/jonas/.local/lib/python3.8/site-packages (from opensearch-py) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jonas/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.4.0->opensearch-py) (2.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install biopython\n",
    "%pip install xmltodict\n",
    "%pip install opensearch-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, BertForSequenceClassification\n",
    "import torch\n",
    "import scipy\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  device = \"cuda:0\" \n",
    "else:  \n",
    "  device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrez.email = \"jonas.gann@gmail.com\"\n",
    "#handle = Entrez.esearch(db=\"pubmed\", term=\"intelligence[tiab]\", retmax=\"10000\")\n",
    "## More information about search field tags: https://pubmed.ncbi.nlm.nih.gov/help/#using-search-field-tags\n",
    "#record = Entrez.read(handle)\n",
    "#id_string = \",\".join(record[\"IdList\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle = Entrez.efetch(db=\"pubmed\", id=id_string, retmode=\"xml\")\n",
    "## info about rettype and retmode: https://www.ncbi.nlm.nih.gov/books/NBK25499/table/chapter4.T._valid_values_of__retmode_and/?report=objectonly\n",
    "#records = Entrez.read(handle)\n",
    "#f = open(\"data.json\", \"w\")\n",
    "#f.write(json.dumps(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data.json\", \"r\")\n",
    "data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[\"PubmedArticle\"]\n",
    "new_data = []\n",
    "for idx, article in enumerate(data):\n",
    "    if (not \"Abstract\" in article[\"MedlineCitation\"][\"Article\"].keys()): continue\n",
    "    article = {\n",
    "        \"id\": article[\"MedlineCitation\"][\"PMID\"],\n",
    "        \"title\": article[\"MedlineCitation\"][\"Article\"][\"ArticleTitle\"],\n",
    "        \"text\": \" \".join(article[\"MedlineCitation\"][\"Article\"][\"Abstract\"][\"AbstractText\"]) # some abstracts are split in an array\n",
    "    }\n",
    "    new_data.append(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PubMedDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = new_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx][\"text\"]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings for questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     inputs = tokenizer([document[\"text\"][:512] for document in new_data], return_tensors=\"pt\", padding=True)\n",
    "#     outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PubMedDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "with torch.no_grad():\n",
    "    for i, sample in enumerate(dataloader):\n",
    "        inputs = tokenizer(sample, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        out = model(**inputs)\n",
    "        pooled = mean_pooling(out, inputs[\"attention_mask\"]).to(\"cpu\")\n",
    "        outputs.extend(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Imact of alcohol on intelligence of children.\"\n",
    "inputs = tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "query_outputs = mean_pooling(model(**inputs), inputs[\"attention_mask\"]).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.stack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = torch.cosine_similarity(out, query_outputs)\n",
    "sorted = torch.argsort(sim, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '37974061',\n",
       " 'title': 'Questioning cognitive heterogeneity and intellectual functioning in fetal alcohol spectrum disorders from the Wechsler intelligence scale for children.',\n",
       " 'text': '<b>Introduction</b>: Fetal Alcohol Spectrum Disorders (FASD) are characterized by a variety of multiple cognitive and behavioral impairments, with intellectual, attentional, and executive impairments being the most commonly reported. In populations with multiple neurodevelopmental disorders, the Full Scale Intelligence Quotient (FSIQ) may not be a proper measure of intellectual abilities, rarely interpreted in FASD clinical practice because the heterogeneity of the cognitive profile is deemed too strong. We propose a quantitative characterization of this heterogeneity, of the strengths and weaknesses profile, and a differential analysis between global cognitive (FSIQ) and elementary reasoning abilities in a large retrospective monocentric FASD sample. <b>Methods</b>: Using clinical and cognitive data (Wechsler Intelligence Scale for Children) from 107 children with FASD, we characterized subject heterogeneity (variance and scatter of scaled/composite scores), searched for strengths and weaknesses, and specified intellectual functioning in terms of FSIQ and elementary reasoning (General Abilities Index, Highest Reasoning Scaled Score), in comparison with standardization norms and a Monte-Carlo-simulated sample from normalization data. <b>Results:</b> Performance of children with FASD was lower on all subtests, with a significant weakness in working memory and processing speed. We found no increase in the variance and scatter of the scores, but a discordance between the assessment of global cognitive functioning (28% borderline, 23% deficient) and that of global and elementary reasoning abilities (23-9% borderline, 15-14% deficient). <b>Conclusion</b>: Our results question the notion of WISC profile heterogeneity in FASD and point to working memory and processing speed over-impairment, with global repercussions but most often preserved elementary reasoning abilities.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[sorted[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
